# 4.Consumer
Topic Partition에서 레코드 조회
```
Properties prop = new Properties();
prop.put("bootstrap.servers", "localhost:9092");
prop.put("group.id", "group1"); //컨슈머 그룹
prop.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); //역직렬화 설정
prop.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(prop);
consumer.subscribe(Collections.singleton("simple")); //토픽 구독

while (조건) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMailis(100));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record.value() + ":" + record.topic() + ":" + record.partition() + ":" + record.offset());
    }
}   

consumer.close();
```

- Topic Partition 그룹 단위 할당
    - Consumer-Group 단위로 Partition 할당
    - 이 때, Partition 개수보다 Consumer-Group이 많아지게 되면 잉여 Consumer 발생   
        → Partition 파트의 "한 개의 Partition은 Consumer-Group의 한 개의 Consumer만 연결 가능"의 개념과 연결   
    ![image](https://user-images.githubusercontent.com/103620466/230827357-84956289-c212-4fa9-93fa-fff690e5cf14.png)   
    - Consumer 개수가 Partition 개수보다 커지면 안되며 만약, 처리량을 위해 Consumer를 늘려야 한다면 Partition의 개수도 같이 늘려야함

### Commit & Offset
#### poll()
1. Consumer poll() 메소드는 이전에 Commit한 오프셋이 존재하면 그 이후의 레코드를 읽어옴
2. 읽어온 오프셋의 마지막 레코드를 Commit
3. 다시 poll() 메소드가 실행되면 앞서 Commit된 오프셋 이후의 레코드를 읽어오는 과정을 반복

#### Commit된 Offset이 없는 경우
- 처음 접근이거나 Commit한 오프셋이 없는 경우
- auto.offset.reset 설정
    - earliset : 맨 처음 오프셋 사용
    - latest : 가장 마지막 오프셋 사용(기본값)
    - none : 이전 Commit이 없으면 Exception 발생 (보통은 사용하지 않음)

### Consumer Setting
#### 조회에 영향을 주는 주요 설정
1. fetch.min.bytes : 조회 시 Broker가 전송할 최소 데이터 크기 (Broker는 해당 설정값 이상의 데이터가 쌓일 때까지 대기)
    - 기본값 : 1
    - 해당 값이 크면 대기 시간은 늘지만 처리량 증가

2. fetch.max.wait.ms : 데이터가 최소 크기가 될 때까지 기다리는 시간
    - 기본값 : 500ms
    - Broker가 리턴할 때까지 대기하는 시간 != Poll 메소드의 대기 시간

3. max.partition.fetch.bytes : Partition당 Server(=Broker)가 리턴할 수 있는 최대 크기
    - 기본값 : 1MB

#### Auto Commit
- enable.auto.commit
    - true : 일정 주기로 Consumer가 읽은 오프셋 Commit(기본값)
    - false : 수동으로 Commit 실행

- auto.commit.interval.ms : 자동 Commit 주기
    - enable.auto.commit가 true인 경우 일정 주기를 설정하는 옵션
    - 기본값 : 5000ms
    - poll(), close() 메소드 호출 시 자동 Commit 실행

#### Manual Commit
- 동기처리
```
ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
for (ConsumerRecords<String, String> record : records) {
    // 처리
}
try {
    consumer.commitSync();
} catch (Exception ex) {
    // 커밋 실패 시 에러 발생
}
```

- 비동기처리
```
ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
for (ConsumerRecords<String, String> record : records) {
    // 처리
}
consumer.commitAsync();
// 성공여부 확인 필요 시 -> commitAsync(OffsetCommitCallback callback)
```

#### 재처리
- 일시적인 커밋 실패, 리밸런스 등에 의해 동일한 메세지 조회 가능
- 따라서, Consumer는 멱등성(idempotence)을 고려
     - 멱등성 : 동일한 요청을 한 번 보내는 것과 여러 번 연속으로 보내는 것이 같은 효과를 지니고, 서버의 상태도 동일하게 남을 때, 해당 HTTP 메서드가 멱등성을 가졌다고 말함
```
ex) 조회수 1 증가 → 좋아요 1 증가 → 조회수 1 증가 : 재처리하는 경우
단순 처리 시 조회수가 2가 아닌 4가 증가할 수 있음
```
- 그렇기 때문에 Consumer는 데이터 특성에 따라 TimeStamp 또는 일련번호 등을 활용하여 데이터를 두 번이상 처리해도 이상 없도록 고려

#### Consumer-Group 유지 방안
- Session Time-out & Heartbeat 
    - Consumer는 Heartbeat를 Broker에 전송해 연결 유지
        - Broker는 일정 시간 Consumer로부터 Heartbeat이 없다면 그룹에서 제외하고 리밸런스 진행
        - session.timeout.ms : 세션타임 아웃시간 (기본값 : 10초)
        - heartbeat.intervla.ms : 하트비트 전송주기 (기본값 : 3초)
        ```
        heartbeat.intervla.ms는 session.timeout.ms의 1/3 이하로 설정하도록 권장
        ```
- max.poll.interval.ms
    - poll() 메소드의 최대 호출 간격
    - 해당 설정 시간이 지나도록 poll이 실행되지 않으면 그룹에서 제외하고 리밸런스 진행

#### 종료처리
- 무한 roop를 돌며 poll() 메소드를 통해 레코드를 읽어올 때 roop를 벗어날 때 사용
- 다른 Tread에서 wakeup() 메소드 호출
- 이때, poll() 메소드는 WakeupException을 발생시키고 이 Exception을 while roop 외부에서 catch
- catch 후 consumer의 close() 메소드 호출
```
KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(prop);
consumer.subscribe(Collections.singleton("simple"));

try {
    while (true) {
        // wakeup() 호출 시 Exception 발생.
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

        // records 처리..
        for (ConsumerRecord<String, String> record : records) {
            System.out.println(record.value() + ":" + record.topic() + ":" + record.partition() + ":" + record.offset());
        }

        try {
            consumer.commitAsync();  
        } catch (Ecception e) {
            e.printStackTrace();
        }
    }   
} catch (Exception ex) {
    //..
} finally {
    consumer.close();
}
```

## 주의사항
- Kafka Consumer는 Tread에 안전하지 않음
    - 여러 Tread에서 동시 사용 금지
    - 단, wakeup() 메소드는 예외
   

## 참조
https://data-make.tistory.com/731   
https://developer.mozilla.org/ko/docs/Glossary/Idempotent   
https://www.youtube.com/@madvirus
